sparse = TRUE)
res = conf_int(model, vcov = "CR2")
model$pval
pvals = 2 * pnorm( abs(res$beta) / res$SE, lower.tail = FALSE )
model$pval; pvals
modTable$Est
model$b
modTable$Est[ modTable$Analysis == "diff" ]
round( model$b, r )
round( model$b, 2 )
res$SE
round( model$b - qnorm(0.975) * res$SE, 2 )
model$b - qnorm(0.975) * res$SE
paste( round( model$b, 2 ),
" [",
round( model$b - qnorm(0.975) * res$SE, 2 ),
", ",
round( model$b + qnorm(0.975) * res$SE, 2 ) )
paste( round( model$b, 2 ),
" [",
round( model$b - qnorm(0.975) * res$SE, 2 ),
", ",
round( model$b + qnorm(0.975) * res$SE, 2 ),\
"]",
sep = "" )
paste( round( model$b, 2 ),
" [",
round( model$b - qnorm(0.975) * res$SE, 2 ),
", ",
round( model$b + qnorm(0.975) * res$SE, 2 ),
"]",
sep = "" )
modTable$Est[ modTable$Analysis == "diff" ]
?conf_int
coef_test(model, vcov = "CR2")
fake=coef_test(model, vcov = "CR2")
coef_test(model, vcov = "CR2")$p_Satt
2 * pnorm( abs(res$beta) / res$SE, lower.tail = FALSE )
source('~/Dropbox/Personal computer/Independent studies/2020/RPCB reproducibility cancer biology/Code (git)/Code/helper.R', echo=TRUE)
#@: meta-regression breaks because changes variable is too homogeneous
# all but one are in the same category
table(do$changes)
#@ TEMPORARILY EXCLUDE THIS MODERATOR:
modVars = c("expAnimal",
"hasCROLab",
"hasCoreLab",
"materialsShared",
"infoQuality")
outcomesWithVar = c( "pw.diff",
"pw.FEest")
# clear the results table to be created
if ( exists("modTable") ) rm(modTable)
for ( i in outcomesWithVar ) {
modTable = safe_analyze_moderators(  .dat = do[ do$quantPair == TRUE, ],
yi.name = i,
# below assumes a standardized naming convention for
#  variances of the pairwise metrics:
vi.name = paste(i, "Var", sep=""),
# cut out the "pw." part of outcome name
analysis.label = gsub("^.*?\\.","",i),
modVars = modVars,
n.tests = length(modVars),
digits = 2 )
}
modTable
table(modTable$Problems)
# ~~ Sanity check for one of the outcomes  ---------------------------------------------
formString = paste( "pw.diff ~ ", paste( modVars, collapse= " + ") )
formString2 = paste( formString, " + (1 | pID / eID)" )
temp = do[ , c("pID", "eID", "pw.diff", "pw.diffVar", modVars ) ]
temp = temp[ complete.cases(temp), ]
V_mat = impute_covariance_matrix(vi = temp$pw.diffVar,
cluster = temp$pID,
r = 0.6)  # just a working "guess"
model = rma.mv( eval( parse(text=formString2) ),
V = V_mat,
random = ~ 1 | pID / eID,
data = temp,
sparse = TRUE)
# robust inference
res = conf_int(model, vcov = "CR2")
pvals = coef_test(model, vcov = "CR2")$p_Satt
#bm
# visually compare model-based inference to robust inference
# pretty similar
model$pval; pvals
resString = paste( round( model$b, 2 ),
" [",
round( model$b - qnorm(0.975) * res$SE, 2 ),
", ",
round( model$b + qnorm(0.975) * res$SE, 2 ),
"]",
sep = "" )
modTable$Est[ modTable$Analysis == "diff" ]
resString
resString = paste( round( model$b, 2 ),
" [",
round( res$CI_L, 2 ),
", ",
round( res$CI_U, 2 ),
"]",
sep = "" )
expect_equal( resString, modTable$Est[ modTable$Analysis == "diff" ] )
resString
modTable$Est[ modTable$Analysis == "diff" ]
resString = paste( round( model$b, 2 ),
format_CI( res$CI_L,
res$CI_U,
digits),
sep = "" )
expect_equal( resString, modTable$Est[ modTable$Analysis == "diff" ] )
format_CI( res$CI_L,
res$CI_U,
digits)
res$CI_L
res$CI_U
resString = paste( round( model$b, 2 ),
format_CI( res$CI_L,
res$CI_U,
2),
sep = "" )
expect_equal( resString, modTable$Est[ modTable$Analysis == "diff" ] )
resString = paste( round( model$b, 2 ),
" ",
format_CI( res$CI_L,
res$CI_U,
2),
sep = "" )
expect_equal( resString, modTable$Est[ modTable$Analysis == "diff" ] )
expect_equal( round(pvals, 2), modTable$Pval[ modTable$Analysis == "diff" ] )
modTable$Pval[ modTable$Analysis == "diff" ]
round(pvals, 2)
expect_equal( as.character( round(pvals, 2) ), modTable$Pval[ modTable$Analysis == "diff" ] )
n.tests
length(modVars)
?coef_test
expect_equal( as.character( round(pvals, 2) ), modTable$Pval[ modTable$Analysis == "diff" ] )
pmax(1, pvals)
expect_equal( as.character( round( pmin(pvals * length(modVars), pvals), 2) ), modTable$Pval.Bonf[ modTable$Analysis == "diff" ] )
pmin(pvals * length(modVars)
round( pmin(pvals * length(modVars) ), 2)
round( pmin(pvals * length(modVars) ), 2 )
expect_equal( as.character( round( pmin(1, pvals * length(modVars) ), 2 ) ), modTable$Pval.Bonf[ modTable$Analysis == "diff" ] )
myBonf = pmin(1, pvals * length(modVars) )
myBonf
format.pval(myBonf)
format_stat(myBonf, 1)
format_stat(myBonf, 0)
format_stat(myBonf, 2)
expect_equal( format_stat(myBonf, 2),
modTable$Pval.Bonf[ modTable$Analysis == "diff" ] )
formString = paste( "pw.Porig ~ ", paste( modVars, collapse= " + ") )
formString2 = paste( formString, " + (1 | pID / eID)" )
temp = do[ , c("pID", "eID", "pw.diff", "pw.diffVar", modVars ) ]
temp = temp[ complete.cases(temp), ]
model = lmer( eval( parse(text=formString2) ),
data = temp )
temp = do[ , c("pID", "eID", "pw.Porig", modVars ) ]
temp = temp[ complete.cases(temp), ]
model = lmer( eval( parse(text=formString2) ),
data = temp )
formString = paste( "pw.Porig ~ ", paste( modVars, collapse= " + ") )
formString2 = paste( formString, " + (1 | pID / eID)" )
temp = do[ , c("pID", "eID", "pw.Porig", modVars ) ]
temp = temp[ complete.cases(temp), ]
model = lmer( eval( parse(text=formString2) ),
data = temp )
outcomesWithoutVar = c("pw.ratio",
"pw.PIRepInside",
"pw.PIRepInside.sens",
"pw.Porig",
"pw.PorigSens",
"pw.PsigAgree1",
"pw.PsigAgree1.sens")
#if ( exists("modTable") ) rm(modTable)
for ( i in outcomesWithoutVar ) {
modTable = safe_analyze_moderators(  .dat = do[ do$quantPair == TRUE, ],
yi.name = i,
# below assumes a standardized naming convention for
vi.name = NA,
# cut out the "pw." part of outcome name
analysis.label = gsub("^.*?\\.","",i),
modVars = modVars,
n.tests = length(modVars),
digits = 2 )
}
# for some reason, the FE problems get deleted
View(modTable)
table(modTable$Problems)
setwd(results.dir)
setwd("Main tables")
write.csv(modTable, "moderator_regressions_outcome_level.csv")
# ~~ Sanity check for one of the outcomes  ---------------------------------------------
formString = paste( "pw.Porig ~ ", paste( modVars, collapse= " + ") )
formString2 = paste( formString, " + (1 | pID / eID)" )
temp = do[ , c("pID", "eID", "pw.Porig", modVars ) ]
temp = temp[ complete.cases(temp), ]
model = lmer( eval( parse(text=formString2) ),
data = temp )
# get robust variances
res = conf_int(model, vcov = "CR2")
?cr2
?coef_test
# robust inference
res = conf_int(model, vcov = "CR2")
pvals = coef_test(model, vcov = "CR2")$p_Satt
# visually compare model-based inference to robust inference
# pretty similar
model$pval; pvals
model
summary(model)
coef(model)
fixef(model)
res
resString = paste( round( fixef(model), 2 ),
" ",
format_CI( res$CI_L,
res$CI_U,
2),
sep = "" )
resString
# check all stats for this outcome
expect_equal( resString, modTable$Est[ modTable$Analysis == "pw.Porig" ] )
modTable$Est[ modTable$Analysis == "pw.Porig" ]
# check all stats for this outcome
expect_equal( resString, modTable$Est[ modTable$Analysis == "Porig" ] )
# check all stats for this outcome
expect_equal( resString, modTable$Est[ modTable$Analysis == "Porig" ] )
expect_equal( as.character( round(pvals, 2) ), modTable$Pval[ modTable$Analysis == "Porig" ] ) # Bonferroni p-values
myBonf = pmin(1, pvals * length(modVars) )
expect_equal( format_stat(myBonf, 2),
modTable$Pval.Bonf[ modTable$Analysis == "Porig" ] )
modTable$Pval[ modTable$Analysis == "Porig" ]
# look at the outcomes to be aggregated
stringsWith( pattern = "pw", x = names(dat) )
# look at the outcomes to be aggregated
stringsWith( pattern = "pw", x = names(do) )
de = do %>%
#filter( quantPair == TRUE ) %>%
group_by(peID) %>%
summarise( nOutcomes = n(),
pw.FEest = mean(pw.FEest),
pw.ratio = mean(pw.ratio),
pw.PIRepInside = mean(pw.PIRepInside),
pw.PIRepInside.sens = mean(pw.PIRepInside.sens),
# @@note: better to suse p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
pw.Porig = harmonic_p(pw.Porig),
pw.Porig.sens = harmonic_p(pw.PorigSens),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
pw.SigAgree = 100* mean(repSignif == origSignif & repDirection == origDirection),
pw.PercSigAgree1 = 100 * mean(pw.PsigAgree1),
pw.PercSigAgree1.sens = 100 * mean(pw.PsigAgree1.sens)
)
View(de)
de = do %>%
#filter( quantPair == TRUE ) %>%
group_by(peID) %>%
summarise( nOutcomes = n(),
pw.FEest = mean(pw.FEest),
pw.ratio = mean(pw.ratio),
pw.PIRepInside = mean(pw.PIRepInside),
pw.PIRepInside.sens = mean(pw.PIRepInside.sens),
# @@note: better to use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
pw.Porig = harmonic_p(pw.Porig),
pw.Porig.sens = harmonic_p(pw.PorigSens),
# overall proportion (within this experiment) expected to agree
pw.SigAgree = 100* mean(repSignif == origSignif &
repDirection == origDirection),
pw.PercSigAgree1 = 100 * mean(pw.PsigAgree1),
pw.PercSigAgree1.sens = 100 * mean(pw.PsigAgree1.sens)
)
de
View(de)
# save it
setwd(prepped.data.dir)
fwrite(de, "prepped_exp_level_data_pw_metrics.csv")
# table does NOT include non-quant pairs
expTable = do %>%
filter( quantPair == TRUE ) %>%
group_by(peID) %>%
summarise( nOutcomes = n(),
origES3 = round( )
FEest = round( mean(pw.FEest), 2 ),
Ratio = round( mean(pw.ratio), 2 ),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better to suse p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = format.pval( harmonic_p(pw.Porig), digits = 2, eps = "0.0001" ),
Porig.sens = format.pval( harmonic_p( pw.PorigSens ), digits = 2, eps = "0.0001" ),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
SigAgree = n_perc_string( repSignif == origSignif & repDirection == origDirection),
PercSigAgree1 = paste( round( 100 * mean(pw.PsigAgree1), 0 ), "%", sep ="" ),
PercSigAgree1.sens = paste( round( 100 * mean(pw.PsigAgree1.sens), 0 ), "%", sep ="" )
)
View(expTable)
expTable = do %>%
filter( quantPair == TRUE ) %>%
group_by(peID) %>%
summarise( nOutcomes = n(),
origES3 = round( mean(origES3, 2) ),
repES3 = round( mean(repES3), 2 ),
FEest = round( mean(pw.FEest), 2 ),
Ratio = round( mean(pw.ratio), 2 ),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better to suse p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = format.pval( harmonic_p(pw.Porig), digits = 2, eps = "0.0001" ),
Porig.sens = format.pval( harmonic_p( pw.PorigSens ), digits = 2, eps = "0.0001" ),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
SigAgree = n_perc_string( repSignif == origSignif & repDirection == origDirection),
PercSigAgree1 = paste( round( 100 * mean(pw.PsigAgree1), 0 ), "%", sep ="" ),
PercSigAgree1.sens = paste( round( 100 * mean(pw.PsigAgree1.sens), 0 ), "%", sep ="" )
)
View(expTable)
# save it
setwd(results.dir)
setwd("Main tables")
fwrite(expTable, "pw_metrics_table_exp_level.csv")
# test only
l = "outcome_level"
#@test only
l = "outcome_level"
if ( l == "outcome_level" ) dat = do
if ( l == "exp_level" ) dat = de
################ SUMMARY METRICS FOR MANUSCRIPT ################
# Percent sign agreement: The percentage of replications whose estimates agree in direction with the original study. This could be heuristically compared to the 50% that would be expected by chance if the null holds exactly in every replication (i.e., no effect heterogeneity) and conditional on all originals’ being positive in sign.
if ( l == "outcome_level" ) {
update_result_csv( name = "n all pairs outcome_level",
value = nrow(dat) )
update_result_csv( name = "n (perc) non-quant pairs outcome_level",
value = n_perc_string(dat$quantPair == FALSE) )
update_result_csv( name = "n (perc) quant pairs outcome_level",
value = n_perc_string(dat$quantPair == TRUE) )
update_result_csv( name = "n (perc) same direction all pairs outcome_level",
value = n_perc_string(dat$repDirection == "Positive") )
}
update_result_csv( name = "n (perc) pw.PIRepInside outcome_level",
value = n_perc_string(dat$pw.PIRepInside == TRUE) )
update_result_csv( name = "n (perc) pw.PIRepInside.sens outcome_level",
value = n_perc_string(dat$pw.PIRepInside.sens == TRUE) )
update_result_csv( name = "Median Porig outcome_level",
value = round( median(dat$pw.Porig, na.rm = TRUE), 3 ) )
update_result_csv( name = "n (perc) Porig<0.005 outcome_level",
value = n_perc_string(dat$pw.Porig < 0.005 ) )
update_result_csv( name = "n (perc) Porig<0.05 outcome_level",
value = n_perc_string(dat$pw.Porig < 0.05 ) )
update_result_csv( name = "Median PorigSens outcome_level",
value = round( median(dat$pw.PorigSens, na.rm = TRUE), 3 ) )
update_result_csv( name = "n (perc) PorigSens<0.005 outcome_level",
value = n_perc_string(dat$pw.PorigSens < 0.005 ) )
update_result_csv( name = "n (perc) PorigSens<0.05 outcome_level",
value = n_perc_string(dat$pw.PorigSens < 0.05 ) )
update_result_csv( name = "Median SMD ratio outcome_level",
value = round( median(dat$pw.ratio, na.rm = TRUE), 2 ) )
update_result_csv( name = "Median SMD diff outcome_level",
value = round( median(dat$pw.diff, na.rm = TRUE), 2 ) )
update_result_csv( name = "Median SMD FEest outcome_level",
value = round( median(dat$pw.FEest, na.rm = TRUE), 2 ) )
update_result_csv( name = "Median SMD origES3 outcome_level",
value = round( median(dat$origES3, na.rm = TRUE), 2 ) )
update_result_csv( name = "Median SMD repES3 outcome_level",
value = round( median(dat$repES3, na.rm = TRUE), 2 ) )
update_result_csv( name = "Mean PsigAgree1 outcome_level",
value = round( mean(dat$pw.PsigAgree1, na.rm = TRUE), 2 ) )
update_result_csv( name = "Mean PsigAgree1.sens outcome_level",
value = round( mean(dat$pw.PsigAgree1.sens, na.rm = TRUE), 2 ) )
################# RPP-STYLE SCATTERPLOT ################
# exclude 2 really extreme originals because they mess up plot scaling
dp = droplevels( dat %>% dplyr::filter(quantPair == TRUE) %>%
filter(origES3 < 50) )
# # randomly sample for testing purposes
# set.seed(2)
# dp = dp %>% group_by(ES2type) %>% sample_n( 3, replace = TRUE )
# #dp = dat[1:10,]
dp$plotID = dp$peoID # with eye toward functionizing
#@move this
dp$expType.pretty = NA
dp$expType.pretty[ dp$expAnimal == TRUE ] = "Animal"
dp$expType.pretty[ dp$expAnimal == FALSE ] = "Not animal"
min( c(dp$origES3, dp$repES3), na.rm = TRUE )
xmin = -4
max( c(dp$origES3, dp$repES3), na.rm = TRUE )
xmax = 30
shapes = c(19, 1)
p = ggplot( data = dp,
aes(x = origES3,
y = repES3,
color = expType.pretty,
shape = repES3 < origES3 ) ) +
# null
geom_abline(intercept = 0,
slope = 1,
lty = 2,
color = "gray") +
geom_hline( yintercept = 0,
lty = 1,
color = "gray" ) +
geom_vline( xintercept = 0,
lty = 1,
color = "gray" ) +
geom_point( size = 2.4,
#pch = 1,
alpha = 1) +
# basic prettifying
theme_bw() +
theme( panel.grid.major=element_blank(),
panel.grid.minor=element_blank() ) +
scale_color_manual( values = colors ) +
scale_shape_manual( values = shapes ) +
scale_x_continuous( limits = c(xmin, xmax), breaks = seq(xmin, xmax, 5) ) +
scale_y_continuous( limits = c(xmin, xmax), breaks = seq(xmin, xmax, 5) ) +
labs( color = "Experiment type",
shape = "Original > replication" ) +
xlab("Original study estimate (SMD)") +
ylab("Replication study estimate (SMD)")
# save it
setwd(results.dir)
setwd("Main figures")
ggsave( paste( "plot_scatter", "_", l, ".pdf", sep = "" ),
width = 6.5,
height = 5)
################# WATERFALL PLOT OF DIFFERENCES ################
dp = dp %>%
arrange( desc(pw.diff) )
dp$ind = 1:nrow(dp)
p = ggplot( ) +
# null
geom_hline(yintercept = 0,
lty = 2,
color = "gray") +
# color-coded by experiment type
geom_point( data = dp,
aes(x = ind,
y = pw.diff,
color = expType.pretty) ) +
geom_errorbar( data = dp,
aes(x = ind,
ymin = pw.diff - qnorm(.975) * sqrt(pw.diffVar),
ymax = pw.diff + qnorm(.975) * sqrt(pw.diffVar),
color = expType.pretty),
alpha = 0.4) +
# basic prettifying
theme_bw() +
theme( panel.grid.major=element_blank(),
panel.grid.minor=element_blank() ) +
scale_color_manual( values = colors ) +
#scale_x_continuous( limits = c(xmin, xmax), breaks = seq(xmin, xmax, 5) ) +
#scale_y_continuous( limits = c(xmin, xmax), breaks = seq(xmin, xmax, 5) ) +
labs( color = "Experiment type" ) +
xlab("Pair") +
ylab("Replication - original estimate (SMD)")
# save it
setwd(results.dir)
setwd("Main figures")
ggsave(paste( "plot_waterfall_diffs", "_", l, ".pdf", sep = "" ),
width = 10,
height = 5)
dp$plotID = dp$peoID # with eye toward functionizing
repColor <- "#0171CE"
origColor <- "#DE4433"
digits = 2
dp = dp %>% arrange( desc(origES3) )
# @move this?
dp$pw.Porig.cat = ">= 0.05"
dp$pw.Porig.cat[ dp$pw.Porig < 0.005 ] = "< 0.005"
dp$pw.Porig.cat[ dp$pw.Porig >= 0.005 & dp$pw.Porig < 0.05 ] = "< 0.05"
Porig.colors = c("red", "black", "gray")
p = ggplot() +
coord_flip() +
# null
geom_vline(xintercept = 0,
lty = 2,
color = "gray") +
# geom_segment(data = dp,
#              aes(y=plotID,
#                  yend=plotID,
#                  x=0,
#                  xend=.5),
#              color="#b2b2b2",
#              size=0.15) +
geom_dumbbell(data=dp,
aes(y=1:nrow(dp),
x=origES3,
xend=repES3,
color = pw.Porig.cat),
size=1.5,
#color="#b2b2b2",
size_x=3,
size_xend = 3,
colour_x = origColor,
colour_xend = repColor) +
scale_color_manual( values = Porig.colors ) +
labs(color = "Porig") +
# basic prettifying
theme_bw() +
theme( panel.grid.major=element_blank(),
panel.grid.minor=element_blank() ) +
xlab("Point estimate") +
ylab("Pair")
# save it
setwd(results.dir)
setwd("Main figures")
ggsave( paste( "plot_dumbbell", "_", l, ".pdf", sep = "" ),
width = 12,
height = 5)
