value = nrow(dat) )
update_result_csv( name = "n (perc) non-quant pairs outcome_level",
value = n_perc_string(dat$quantPair == FALSE) )
update_result_csv( name = "n (perc) quant pairs outcome_level",
value = n_perc_string(dat$quantPair == TRUE) )
update_result_csv( name = "n (perc) same direction all pairs outcome_level",
value = n_perc_string(dat$repDirection == "Positive") )
}
update_result_csv( name = "n (perc) pw.PIRepInside outcome_level",
value = n_perc_string(dat$pw.PIRepInside == TRUE) )
update_result_csv( name = "n (perc) pw.PIRepInside.sens outcome_level",
value = n_perc_string(dat$pw.PIRepInside.sens == TRUE) )
update_result_csv( name = "Median Porig outcome_level",
value = round( median(dat$pw.Porig, na.rm = TRUE), 3 ) )
update_result_csv( name = "n (perc) Porig<0.005 outcome_level",
value = n_perc_string(dat$pw.Porig < 0.005 ) )
update_result_csv( name = "n (perc) Porig<0.05 outcome_level",
value = n_perc_string(dat$pw.Porig < 0.05 ) )
update_result_csv( name = "Median PorigSens outcome_level",
value = round( median(dat$pw.PorigSens, na.rm = TRUE), 3 ) )
update_result_csv( name = "n (perc) PorigSens<0.005 outcome_level",
value = n_perc_string(dat$pw.PorigSens < 0.005 ) )
update_result_csv( name = "n (perc) PorigSens<0.05 outcome_level",
value = n_perc_string(dat$pw.PorigSens < 0.05 ) )
update_result_csv( name = "Median SMD ratio outcome_level",
value = round( median(dat$pw.ratio, na.rm = TRUE), 2 ) )
update_result_csv( name = "Median SMD diff outcome_level",
value = round( median(dat$pw.diff, na.rm = TRUE), 2 ) )
update_result_csv( name = "Median SMD FEest outcome_level",
value = round( median(dat$pw.FEest, na.rm = TRUE), 2 ) )
update_result_csv( name = "Mean PsigAgree1 outcome_level",
value = round( mean(dat$pw.PsigAgree1, na.rm = TRUE), 2 ) )
vr()
update_result_csv( name = "Median SMD origES3 outcome_level",
value = round( median(dat$origES3, na.rm = TRUE), 2 ) )
update_result_csv( name = "Median SMD repES3 outcome_level",
value = round( median(dat$repES3, na.rm = TRUE), 2 ) )
vr()
names(do)
head(cd)
names(do)
# this includes only the new variables added to outcome-level data
newVars = names(do)[104: length(names(do))]
newVars
cb2 = data.frame( variable = newVars,
type = NA,
description = NA )
cb2
cb2[ "variable" == "repSignif", c("type", "description") ]
cb2[ "variable" == "repSignif", c("type", "description") ] = c("bin", "Was replication p<0.05?")
cb2
cb2[ cb2$variable == "repSignif", c("type", "description") ]
cb2[ cb2$variable == "repSignif", c("type", "description") ] = c("bin", "Was replication p<0.05?")
cb2
# codebook
cb2 = data.frame( variable = newVars,
type = NA,
description = NA )
# vec: vector of type and description
update_codebook_row = function(var, vec) {
cb2[ cb2$variable == var, c("type", "description") ] = vec
}
update_codebook_row("repSignif") = c("bin", "Was replication p<0.05?")
update_codebook_row( "repSignif", c("bin", "Was replication p<0.05?") )
cb2
# vec: vector of type and description
update_codebook_row = function(var, vec) {
cb2[ cb2$variable == var, c("type", "description") ] <<- vec
}
update_codebook_row( "repSignif", c("bin", "Was replication p<0.05?") )
cb2
update_codebook_row( "repSignif", c("bin", "Was replication p<0.05?") )
update_codebook_row( "origSignif", c("bin", "Was original p<0.05?") )
update_codebook_row( "quantPair", c("bin", "Did we have quantitative ES for both original and replication?") )
update_codebook_row( "origES2", c("num", "A meta-analyzable effect size obtained from ES (e.g., log-HR instead of HR), but NOT necessarily an SMD") )
update_codebook_row( "ES2Type", c("char", "Scale of ES2") )
cb2
update_codebook_row( "repSignif", c("bin", "Was replication p<0.05?") )
update_codebook_row( "origSignif", c("bin", "Was original p<0.05?") )
update_codebook_row( "quantPair", c("bin", "Did we have quantitative ES for both original and replication?") )
update_codebook_row( "origES2", c("num", "A meta-analyzable effect size obtained from ES (e.g., log-HR instead of HR), but NOT necessarily an SMD") )
update_codebook_row( "ES2Type", c("char", "Scale of ES2") )
update_codebook_row( "origES3", c("num", "A meta-analyzable effect size on the SMD scale") )
update_codebook_row( "pw.PIRepInside", c("bin", "Was replication inside 95% PI?") )
update_codebook_row( "pw.PIRepInsid.sens", c("bin", "Was replication inside 95% PI, allowing for hypothetical heterogeneity?") )
update_codebook_row( "pw.Porig", c("num", "p-value for original inconsistency with replication") )
update_codebook_row( "pw.PorigSens", c("num", "p-value for original inconsistency with replication, allowing for hypothetical heterogeneity") )
update_codebook_row( "pw.ratio", c("num", "origES3 / repES3") )
update_codebook_row( "pw.diff", c("num", "origES3 - repES3") )
update_codebook_row( "pw.PsigAgree1", c("num", "Expected probability of significance agreement under null (Mathur & VanderWeele)") )
update_codebook_row( "pw.FEest", c("num", "Fixed-effects estimate pooling original and replication") )
cb2
View(cb2)
setwd(prepped.data.dir)
fwrite(cb2, "codebook_for_prepped_data.csv")
root.dir = "~/Dropbox/Personal computer/Independent studies/2020/RPCB reproducibility cancer biology/Code (git)"
raw.data.dir = paste(root.dir, "Raw data", sep="/")
prepped.data.dir = paste(root.dir, "Prepped data", sep="/")
code.dir = paste(root.dir, "Code", sep="/")
setwd(code.dir)
source("helper.R")
# should View2() open tabs?
useView = FALSE
# should we run sanity checks?
run.sanity = FALSE
# read in paper-, experiment-, and outcome-level data
setwd(raw.data.dir)
# we won't actually be using the first of these
dp = read_xlsx("2020_11_30_raw_data.xlsx", sheet = "Paper level data"); nrow(dp)
de = read_xlsx("2020_11_30_raw_data.xlsx", sheet = "Experiment level data"); nrow(de)
do = read_xlsx("2020_11_30_raw_data.xlsx", sheet = "Outcome level data"); nrow(do)
##### Sanity Checks on Hierarchical Data Structure #####
# nesting levels: paper > experiment > outcome
names(de)
# exp-level data have 193 unique paper-exp combos
uni( paste(de$`Paper #`, de$`Experiment #` ) )
# and 53 papers
uni(de$`Paper #`)
# outcome-level data have only 50 unique paper-exp combos
uni( paste(do$`Paper #`, do$`Experiment #` ) )
# and 23 papers
uni(do$`Paper #`)
# outcome-level only contains ones with quantitative effect sizes
table( is.na(do$`Original effect size`))
# confirm that outcome-level data have all papers from exp-level data for
#  which the replication was completed
expect_equal( uni(de$`Paper #`[de$`Replication experiment completed` == "Yes"]),
uni(do$`Paper #`) )
##### Look at What Info Is in Each Dataset #####
# variables that only appear in one or the other dataset
names(do)[ !names(do) %in% names(de) ]
names(de)[ !names(de) %in% names(do) ]  # moderators
# anything non-overlapping in paper-level data?
names(dp)[ !names(dp) %in% c(names(de), names(do)) ]
# variables in both datasets
names(do)[ names(do) %in% names(de) ]
names(dp)[ names(dp) %in% names(de) ]
##### Merge Datasets #####
d = merge( do, de, by = c("Paper #", "Experiment #"), all=TRUE )
nrow(d)
# because de has a superset of do's papers and experiments:
expect_equal( uni(d$`Paper #`), uni(de$`Paper #`) )
expect_equal( uni(d$`Experiment #`), uni(de$`Experiment #`) )
# this time don't keep papers that don't even give experiment-level data
# i.e., left-join
d = merge( d, dp, by = "Paper #", all.x = TRUE)
nrow(d)
root.dir = "~/Dropbox/Personal computer/Independent studies/2020/RPCB reproducibility cancer biology/Code (git)"
raw.data.dir = paste(root.dir, "Raw data", sep="/")
prepped.data.dir = paste(root.dir, "Prepped data", sep="/")
code.dir = paste(root.dir, "Code", sep="/")
results.dir = paste(root.dir, "Results from R", sep="/")
# no sci notation
options(scipen=999)
# for plots
colors = c("red", "black")
setwd(code.dir)
source("helper.R")
setwd(prepped.data.dir)
do = fread("prepped_outcome_level_data.csv")
# read in codebook for easy searching
setwd(raw.data.dir)
cd = fread("codebook_merged.csv")
dp = dp %>%
arrange( desc(pw.diff) )
dp$ind = 1:nrow(dp)
# High-level summary of this script:
#  - Calculates pairwise metrics at the outcome level
#  - Then aggregates these at the experiment level to create an experiment-level datasets
#  - Conducts remaining analyses at both levels of analysis (outcome, experiment)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#                                     PRELIMINARIES                                 #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
rm(list=ls())
library(readxl)
library(dplyr)
library(ggplot2)
library(MetaUtility)
library(robumeta)
library(testthat)
library(Replicate)
library(data.table)
library(metafor)
library(here)
library(ggalt)
library(tidyverse)
# @@fix relative path problem:
#set_here("~/Dropbox/Personal computer/Independent studies/2020/RPCB reproducibility cancer biology")
# here()
root.dir = "~/Dropbox/Personal computer/Independent studies/2020/RPCB reproducibility cancer biology/Code (git)"
raw.data.dir = paste(root.dir, "Raw data", sep="/")
prepped.data.dir = paste(root.dir, "Prepped data", sep="/")
code.dir = paste(root.dir, "Code", sep="/")
results.dir = paste(root.dir, "Results from R", sep="/")
# no sci notation
options(scipen=999)
# for plots
colors = c("red", "black")
setwd(code.dir)
source("helper.R")
setwd(prepped.data.dir)
do = fread("prepped_outcome_level_data.csv")
# read in codebook for easy searching
setwd(raw.data.dir)
cd = fread("codebook_merged.csv")
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#               WORK ON OUTCOME-LEVEL DATA: CALCULATE PAIRWISE METRICS              #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
################################ CALCULATE PAIRWISE METRICS ################################
# all the pw.XXX metrics are calculating using the ES3's (i.e., SMDs)
# retain non-quant pairs since we will also create plots and metrics for those below
do = do %>%
rowwise() %>%
mutate( analyze_one_row(origES3,
origVar3,
repES3,
repVar3) )
# # ratio sanity checks:fexptable
# # @@note that some ratios and their variances are extremely large:
# inds = which(do$pw.ratioVar > 100000)
# do$pw.ratio[inds]
#
# i = 5
# origES2 = do$origES2[i]
# origVar2 = do$origVar2[i]
# repES2 = do$repES2[i]
# repVar2 = do$repVar2[i]
#
# deltamethod( ~ x1/x2,
#              mean = c( origES2, repES2 ), cov = diag( c(origVar2, repVar2) ) )^2
#
#
# for ( i in 1:nrow(do) ) {
#   # debug any rows that are brats
#   chunk = analyze_one_row( do$origES2[i],
#                    do$origVar2[i],
#                    do$repES2[i],
#                    do$repVar2[i],
#                    do$ES2type[i])
#   if ( i == 1 ) res = chunk
#   if ( i > 1) res = rbind(res, chunk)
#
# }
# save it
setwd(prepped.data.dir)
fwrite(do, "prepped_outcome_level_data_pw_metrics.csv")
################################ MAKE CODEBOOK ################################
# this includes only the new variables added to outcome-level data
newVars = names(do)[104: length(names(do))]
# codebook
cb2 = data.frame( variable = newVars,
type = NA,
description = NA )
# vec: vector of type and description
update_codebook_row = function(var, vec) {
cb2[ cb2$variable == var, c("type", "description") ] <<- vec
}
update_codebook_row( "repSignif", c("bin", "Was replication p<0.05?") )
update_codebook_row( "origSignif", c("bin", "Was original p<0.05?") )
update_codebook_row( "quantPair", c("bin", "Did we have quantitative ES for both original and replication?") )
update_codebook_row( "origES2", c("num", "A meta-analyzable effect size obtained from ES (e.g., log-HR instead of HR), but NOT necessarily an SMD") )
update_codebook_row( "ES2Type", c("char", "Scale of ES2") )
update_codebook_row( "origES3", c("num", "A meta-analyzable effect size on the SMD scale") )
update_codebook_row( "pw.PIRepInside", c("bin", "Was replication inside 95% PI?") )
update_codebook_row( "pw.PIRepInsid.sens", c("bin", "Was replication inside 95% PI, allowing for hypothetical heterogeneity?") )
update_codebook_row( "pw.Porig", c("num", "p-value for original inconsistency with replication") )
update_codebook_row( "pw.PorigSens", c("num", "p-value for original inconsistency with replication, allowing for hypothetical heterogeneity") )
update_codebook_row( "pw.ratio", c("num", "origES3 / repES3") )
update_codebook_row( "pw.diff", c("num", "origES3 - repES3") )
update_codebook_row( "pw.PsigAgree1", c("num", "Expected probability of significance agreement under null (Mathur & VanderWeele)") )
update_codebook_row( "pw.FEest", c("num", "Fixed-effects estimate pooling original and replication") )
# save it
setwd(prepped.data.dir)
fwrite(cb2, "codebook_for_prepped_data.csv")
################################ META-REGRESSION ################################
# moderators are at experiment-level, but analysis is at outcome level with
#  nesting to handle experiment-level and paper-level correlation structure
# We will report the above metrics for each pair. Additionally, to summarize the above three metrics across pairs while accounting for their possible non-independence, we will robustly meta-regress each metric in a manner that accounts for clustering within original studies (Hedges et al., 2010). This model provides asymptotically correct inference even when the clustering structure is misspecified, which is important here because of the difficulty of precisely specifying the complex nature of clustering. This will yield average values of Porig, the difference, and the fixed-effects pooled estimate across all pairs.
# Moderators:
# Animal vs. non-animal
# Type of replication lab (contract research organization [CRO] vs. academic core lab)
# What was requested from original authors and the response? (scored subjectively; Likert scale)
# Was a post hoc modification to protocol needed to complete the experiment? (col W in experiment level)
#@@Might be problematic (think about):
# N of original
# ES of original
##### Moderator Summary Table and Correlation Matrix #####
# must use dummies for labType here to get correlations
modVars = c("expAnimal",
"labType_b.Both",
"labType_c.CRO.only",
"reqAntibodies",
"reqCells",
"reqPlasmids",
"responseQuality",
"changesNeeded")
CreateTableOne(vars = modVars, data = do)
# moderator correlation matrix
library(corrr)
corrs = do %>%
filter(quantPair == TRUE) %>%
select(modVars) %>%
correlate( use = "pairwise.complete.obs" ) %>%
stretch() %>%
arrange(desc(r)) %>%
group_by(r) %>%
filter(row_number()==1)
corrs$r = round(corrs$r, 2)
corrs = corrs[ !is.na(corrs$r), ]
View(corrs)
# save it
setwd(results.dir)
setwd("Additional tables and figures")
write.csv(corrs, "moderator_cormat.csv")
##### Analyze Pairwise Metrics That *Do* Have Variances #####
# not surprisingly given its extreme values and variances, ratio doesn't really work here (V not positive definite)
outcomesWithVar = c( "pw.diff",
"pw.FEest")
# clear the results table to be created
if ( exists("modTable") ) rm(modTable)
for ( i in outcomesWithVar ) {
modTable = safe_analyze_moderators(  .dat = do[ do$quantPair == TRUE, ],
yi.name = i,
# below assumes a standardized naming convention for
#  variances of the pairwise metrics:
vi.name = paste(i, "Var", sep=""),
# cut out the "pw." part of outcome name
analysis.label = strsplit(i, "[.]")[[1]][2],
modVars = modVars,
n.tests = length(modVars),
digits = 2 )
}
modTable
table(modTable$Problems)
##### Analyze Pairwise Metrics That *Don't* Have Variances #####
outcomesWithoutVar = c("pw.ratio",
"pw.PIRepInside",
"pw.PIRepInside.sens",
"pw.Porig",
"pw.PorigSens",
"pw.PsigAgree1")
#if ( exists("modTable") ) rm(modTable)
for ( i in outcomesWithoutVar ) {
modTable = safe_analyze_moderators(  .dat = do[ do$quantPair == TRUE, ],
yi.name = i,
# below assumes a standardized naming convention for
vi.name = NA,
# cut out the "pw." part of outcome name
analysis.label = strsplit(i, "[.]")[[1]][2],
modVars = modVars,
n.tests = length(modVars),
digits = 2 )
}
# for some reason, the FE problems get deleted
View(modTable)
table(modTable$Problems)
setwd(results.dir)
setwd("Main tables")
write.csv(modTable, "moderator_regressions_outcome_level.csv")
################################ CREATE EXPT-LEVEL DATASET AND TABLE ################################
# table of pairwise metrics aggregated sat the experiment level (~50 rows)
# look at the outcomes to be aggregated
stringsWith( pattern = "pw", x = names(dat) )
##### Dataset #####
# @@to do:
# - aggregate origES3, etc., so we can make the difference plot
# # FE meta-analysis of original and replications
# FEmod = rma.uni( yi = c(origES3, repES3),
#                  vi = c(origVar3, repVar3),
#                  method = "FE")
# entries are numerical and not rounded for plotting, analysis, etc.
# this DOES include the non-quant pairs for plotting purposes
# keep pw.XXX variable names the same to facilitate automated plotting below
de = do %>%
#filter( quantPair == TRUE ) %>%
group_by(peID) %>%
summarise( nOutcomes = n(),
pw.FEest = mean(pw.FEest),
pw.ratio = mean(pw.ratio),
pw.PIRepInside = mean(pw.PIRepInside),
pw.PIRepInside.sens = mean(pw.PIRepInside.sens),
# @@note: better to suse p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
pw.Porig = harmonic_p(pw.Porig),
pw.Porig.sens = harmonic_p(pw.PorigSens),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
pw.SigAgree = 100* mean(repSignif == origSignif & repDirection == origDirection),
pw.PercSigAgree1 = 100 * mean(pw.PsigAgree1)
)
View(de)
# save it
setwd(prepped.data.dir)
fwrite(de, "prepped_exp_level_data_pw_metrics.csv")
##### Table #####
# table does NOT include non-quant pairs
expTable = do %>%
filter( quantPair == TRUE ) %>%
group_by(peID) %>%
summarise( nOutcomes = n(),
origES3 = round( )
FEest = round( mean(pw.FEest), 2 ),
Ratio = round( mean(pw.ratio), 2 ),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better to suse p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = format.pval( harmonic_p(pw.Porig), digits = 2, eps = "0.0001" ),
Porig.sens = format.pval( harmonic_p( pw.PorigSens ), digits = 2, eps = "0.0001" ),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
SigAgree = n_perc_string( repSignif == origSignif & repDirection == origDirection),
PercSigAgree1 = paste( round( 100 * mean(pw.PsigAgree1), 0 ), "%", sep ="" )
)
View(expTable)
# save it
setwd(results.dir)
setwd("Main tables")
fwrite(expTable, "pw_metrics_table_exp_level.csv")
# test only
l = "outcome_level"
if ( l == "outcome_level" ) dat = do
if ( l == "exp_level" ) dat = de
dp = dp %>%
arrange( desc(pw.diff) )
dp$ind = 1:nrow(dp)
# exclude 2 really extreme originals because they mess up plot scaling
dp = droplevels( dat %>% dplyr::filter(quantPair == TRUE) %>%
filter(origES3 < 50) )
pw_metrics_table_exp_level.csv
head(dp)
################# WATERFALL PLOT OF DIFFERENCES ################
dp = dp %>%
arrange( desc(pw.diff) )
dp$ind = 1:nrow(dp)
p = ggplot( ) +
# null
geom_hline(yintercept = 0,
lty = 2,
color = "gray") +
# color-coded by experiment type
geom_point( data = dp,
aes(x = ind,
y = pw.diff,
color = expType.pretty) ) +
geom_errorbar( data = dp,
aes(x = ind,
ymin = pw.diff - qnorm(.975) * sqrt(pw.diffVar),
ymax = pw.diff + qnorm(.975) * sqrt(pw.diffVar),
color = expType.pretty),
alpha = 0.4) +
# basic prettifying
theme_bw() +
theme( panel.grid.major=element_blank(),
panel.grid.minor=element_blank() ) +
scale_color_manual( values = colors ) +
#scale_x_continuous( limits = c(xmin, xmax), breaks = seq(xmin, xmax, 5) ) +
#scale_y_continuous( limits = c(xmin, xmax), breaks = seq(xmin, xmax, 5) ) +
labs( color = "Experiment type" ) +
xlab("Pair") +
ylab("Replication - original estimate (SMD)")
p
# # randomly sample for testing purposes
# set.seed(2)
# dp = dp %>% group_by(ES2type) %>% sample_n( 3, replace = TRUE )
# #dp = dat[1:10,]
dp$plotID = dp$peoID # with eye toward functionizing
#@move this
dp$expType.pretty = NA
dp$expType.pretty[ dp$expAnimal == TRUE ] = "Animal"
dp$expType.pretty[ dp$expAnimal == FALSE ] = "Not animal"
dp = dp %>%
arrange( desc(pw.diff) )
dp$ind = 1:nrow(dp)
p = ggplot( ) +
# null
geom_hline(yintercept = 0,
lty = 2,
color = "gray") +
# color-coded by experiment type
geom_point( data = dp,
aes(x = ind,
y = pw.diff,
color = expType.pretty) ) +
geom_errorbar( data = dp,
aes(x = ind,
ymin = pw.diff - qnorm(.975) * sqrt(pw.diffVar),
ymax = pw.diff + qnorm(.975) * sqrt(pw.diffVar),
color = expType.pretty),
alpha = 0.4) +
# basic prettifying
theme_bw() +
theme( panel.grid.major=element_blank(),
panel.grid.minor=element_blank() ) +
scale_color_manual( values = colors ) +
#scale_x_continuous( limits = c(xmin, xmax), breaks = seq(xmin, xmax, 5) ) +
#scale_y_continuous( limits = c(xmin, xmax), breaks = seq(xmin, xmax, 5) ) +
labs( color = "Experiment type" ) +
xlab("Pair") +
ylab("Replication - original estimate (SMD)")
# save it
setwd(results.dir)
setwd("Main figures")
ggsave(paste( "plot_waterfall_diffs", "_", l, ".pdf", sep = "" ),
width = 5,
height = 10)
# save it
setwd(results.dir)
setwd("Main figures")
ggsave(paste( "plot_waterfall_diffs", "_", l, ".pdf", sep = "" ),
width = 10,
height = 5)
