n_perc_string( c(0,0,0,0,1,1,1,0,0) )
# aggregation fns:
# plain mean (ratio)
# count and percent (repinside, PsigAGree)
# FE analysis (FEest)
# harmonic mean p-value (porig)
dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside)
)
library(harmonicmeanp)
dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
Porig = p.hmp(pw.Porig)  )
p.hmp(dat$pw.Porig)
p.hmp(dat$pw.Porig[!is.na(dat$pw.Porig)])
dat$pw.Porig
x =dat$pw.Porig[!is.na(dat$pw.Porig)]
p.hmp(dat$pw.Porig[!is.na(dat$pw.Porig)])
x
p.hmp(p=x)
hmp.stat(p=x)
dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = hmp.stat( pw.Porig[ !is.na(pw.Porig) ] )  )
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = hmp.stat( pw.Porig[ !is.na(pw.Porig) ] )  )
View(expTable)
harmomic_p = function(x) {
if ( all( is.na(x) ) ) return("All missing")
hmp.stat( x[ !is.na(x) ] )
}
harmomic_p = function(x) {
library(harmonicmeanp)
if ( all( is.na(x) ) ) return("All missing")
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
hmp.stat( x[ !is.na(x) ] )
}
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = harmonic_p( pw.Porig )  )
View(expTable)
harmomic_p = function(x) {
library(harmonicmeanp)
if ( all( is.na(x) ) ) return("All missing")
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
hmp.stat( x[ !is.na(x) ] )
}
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = harmonic_p( pw.Porig )  )
harmonic_p = function(x) {
library(harmonicmeanp)
if ( all( is.na(x) ) ) return("All missing")
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
hmp.stat( x[ !is.na(x) ] )
}
# aggregation fns:
# plain mean (ratio)
# count and percent (repinside, PsigAGree)
# FE analysis (FEest)
# harmonic mean p-value (porig)
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = harmonic_p( pw.Porig )  )
View(expTable)
x =dat$pw.Porig[
)
harmonic_p = function(x) {
library(harmonicmeanp)
if ( all( is.na(x) ) ) return(NA)
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
hmp.stat( x[ !is.na(x) ] )
}
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = harmonic_p( pw.Porig )  )
View(expTable)
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = harmonic_p( pw.Porig ),
Porig.sens = harmonic_p( pw.PorigSens ),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
SigAgree = n_perc_string( repSignif == origSignif & repDirection == origDirection),
PsigAgree1 = mean(pw.PsigAgree1),
)
View(expTable)
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = harmonic_p( pw.Porig ),
Porig.sens = harmonic_p( pw.PorigSens ),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
SigAgree = n_perc_string( repSignif == origSignif & repDirection == origDirection),
PercSigAgree1 = paste( round( 100 * mean(pw.PsigAgree1), 0 ), "%", sep ="" )
)
View(expTable)
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
Ratio = round( mean(pw.ratio), 2 ),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = harmonic_p( pw.Porig ),
Porig.sens = harmonic_p( pw.PorigSens ),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
SigAgree = n_perc_string( repSignif == origSignif & repDirection == origDirection),
PercSigAgree1 = paste( round( 100 * mean(pw.PsigAgree1), 0 ), "%", sep ="" )
)
table(d3$EStype2)
table(d$EStype2)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#                              PRELIMINARIES                                #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
rm(list=ls())
library(readxl)
library(dplyr)
library(ggplot2)
library(MetaUtility)
library(robumeta)
library(testthat)
library(Replicate)
library(data.table)
library(metafor)
root.dir = "~/Dropbox/Personal computer/Independent studies/2020/RPCB reproducibility cancer biology"
raw.data.dir = paste(root.dir, "Raw data", sep="/")
prepped.data.dir = paste(root.dir, "Prepped data", sep="/")
code.dir = paste(root.dir, "Code (git)", sep="/")
results.dir = paste(root.dir, "Results from R", sep="/")
options(scipen=999)
setwd(code.dir)
source("helper.R")
setwd(prepped.data.dir)
d = fread("prepped_outcome_level_data.csv")
# read in codebook for easy searching
setwd(raw.data.dir)
cd = fread("codebook_merged.csv")
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#                              PRELIMINARIES                                #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
rm(list=ls())
library(readxl)
library(dplyr)
library(ggplot2)
library(MetaUtility)
library(robumeta)
library(testthat)
library(Replicate)
library(data.table)
library(metafor)
root.dir = "~/Dropbox/Personal computer/Independent studies/2020/RPCB reproducibility cancer biology"
raw.data.dir = paste(root.dir, "Raw data", sep="/")
prepped.data.dir = paste(root.dir, "Prepped data", sep="/")
code.dir = paste(root.dir, "Code (git)", sep="/")
results.dir = paste(root.dir, "Results from R", sep="/")
options(scipen=999)
setwd(code.dir)
source("helper.R")
setwd(prepped.data.dir)
d = fread("prepped_outcome_level_data.csv")
# read in codebook for easy searching
setwd(raw.data.dir)
cd = fread("codebook_merged.csv")
# d = read_xlsx("RP_CB Final Analysis .xlsx")
#
# names(d)
#
#
# dim(d)  # 258
#
# table(d$`Replication attempted`)  # 233
# table(d$`Experiment completed`) # 190
#
# d %>% filter( `Experiment completed` == "Yes" ) %>%
#   summarise( length(unique(`Original study title`)),
#              mean(`Number of lab(s) contracted for the entire study`) )
#
# data.frame( d %>% group_by(`Original study title`) %>%
#               summarise( n(),
#                          comp = mean(`Experiment completed` == "Yes"),
#                          expN0 = max(`Experiment #`, na.rm = TRUE),
#                          max(`Study #`, na.rm = TRUE) ) )
####################################
# We will conduct the main analyses at two levels of granularity (outcome-level and experiment-level).
# distinctions in analysis:
#  - completed pairs (has realized replication outcome) vs. all pairs
#
# with eye toward functionizing everything later (so we can do for outcome- and exp-level):
dat = d
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#                     METRICS FOR ALL PAIRS (INCL NON-COMPLETED)                                #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
# Percent sign agreement: The percentage of replications whose estimates agree in direction with the original study. This could be heuristically compared to the 50% that would be expected by chance if the null holds exactly in every replication (i.e., no effect heterogeneity) and conditional on all originalsâ€™ being positive in sign.
table(dat$origDirection, dat$repDirection, useNA = "ifany")
mean( dat$repDirection == "Positive" )
sum( dat$repDirection == "Positive" )
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
#              MAIN PAIRWISE METRICS (COMPLETED QUANT PAIRS)                        #
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
################################ CALCULATE PAIRWISE METRICS ################################
# Primary: Prediction interval and whether replication falls inside it (assuming t2=0)
# Make forest plot of these, including Porig on the side
# Primary: Porig
# Primary: Ratio of original to replication study estimates
# Secondary: P(Replication p < .05) with 2 expectation benchmarks
#  - from JRSSA paper
#  - the true effect size in each original is equal to the effect size for which it would
#   have had 80% power.
# Porig with assumed zero heterogeneity
# Fixed-effects pooled estimate: A meta-analytic pooled estimate of the original and replication estimates from each pair.
# As sensitivity analysis:
# Porig and pred interval with imputed heterogeneity: If there is moderate or high within-pair effect heterogeneity, this could make the original studies appear less consistent with the replications than they truly are. As a sensitivity analysis, we will impute the average heterogeneity estimate from Olsson-Collentine, et al. (in press), which was tau=0.13 on the SMD scale, and use this to re-calculate Porig for each pair. These values of Porig will likely be large (i.e., indicating better consistency) than those from main analyses.
# dataset has already been aggregated to either the outcome- or the experiment-level
# if this hits errors, it's likely that you have mismatches in the NA dataframe vs. the filled-in one in analyze_one_row
dat = dat %>%
rowwise() %>%
mutate( analyze_one_row(origES2,
origVar2,
repES2,
repVar2,
ES2type) )
# # ratio sanity checks:
# # @@note that some ratios and their variances are extremely large:
# inds = which(dat$pw.ratioVar > 100000)
# dat$pw.ratio[inds]
#
# i = 5
# origES2 = dat$origES2[i]
# origVar2 = dat$origVar2[i]
# repES2 = dat$repES2[i]
# repVar2 = dat$repVar2[i]
#
# deltamethod( ~ x1/x2,
#              mean = c( origES2, repES2 ), cov = diag( c(origVar2, repVar2) ) )^2
#
#
# for ( i in 1:nrow(dat) ) {
#   # debug any rows that are brats
#   chunk = analyze_one_row( dat$origES2[i],
#                    dat$origVar2[i],
#                    dat$repES2[i],
#                    dat$repVar2[i],
#                    dat$ES2type[i])
#   if ( i == 1 ) res = chunk
#   if ( i > 1) res = rbind(res, chunk)
#
# }
################################ META-REGRESSION ################################
# moderators are at experiment-level, but analysis is at outcome level with
#  nesting to handle experiment-level and paper-level correlation structure
# We will report the above metrics for each pair. Additionally, to summarize the above three metrics across pairs while accounting for their possible non-independence, we will robustly meta-regress each metric in a manner that accounts for clustering within original studies (Hedges et al., 2010). This model provides asymptotically correct inference even when the clustering structure is misspecified, which is important here because of the difficulty of precisely specifying the complex nature of clustering. This will yield average values of Porig, the difference, and the fixed-effects pooled estimate across all pairs.
# Moderators:
# Animal vs. non-animal
# Type of replication lab (contract research organization [CRO] vs. academic core lab)
# What was requested from original authors and the response? (scored subjectively; Likert scale)
# Was a post hoc modification to protocol needed to complete the experiment? (col W in experiment level)
#@@Might be problematic (think about):
# N of original
# ES of original
##### Moderator Summary Table and Correlation Matrix #####
# must use dummies for labType here to get correlations
modVars = c("expAnimal",
"labType_b.Both",
"labType_c.CRO.only",
"reqAntibodies",
"reqCells",
"reqPlasmids",
"responseQuality",
"changesNeeded")
CreateTableOne(vars = modVars, data = dat)
library(corrr)
corrs = dat %>% select(modVars) %>%
correlate( use = "pairwise.complete.obs" ) %>%
stretch() %>%
arrange(desc(r)) %>%
group_by(r) %>%
filter(row_number()==1)
corrs$r = round(corrs$r, 2)
corrs = corrs[ !is.na(corrs$r), ]
View(corrs)
setwd(results.dir)
setwd("Tables to prettify")
write.csv(corrs, "moderator_cormat.csv")
##### Analyze Pairwise Metrics That *Do* Have Variances #####
# not surprisingly given its extreme values and variances, ratio doesn't really work here (V not positive definite)
outcomesWithVar = c( #"pw.ratio",
"pw.FEest")
# clear the results table to be created
if ( exists("modTable") ) rm(modTable)
for ( i in outcomesWithVar ) {
modTable = safe_analyze_moderators(  .dat = dat,
yi.name = i,
# below assumes a standardized naming convention for
#  variances of the pairwise metrics:
vi.name = paste(i, "Var", sep=""),
# cut out the "pw." part of outcome name
analysis.label = strsplit(i, "[.]")[[1]][2],
modVars = modVars,
n.tests = length(modVars),
digits = 2 )
}
modTable
table(modTable$Problems)
##### Analyze Pairwise Metrics That *Don't* Have Variances #####
outcomesWithoutVar = c("pw.ratio",
"pw.PIRepInside",
"pw.PIRepInside.sens",
"pw.Porig",
"pw.PorigSens",
"pw.PsigAgree1")
#if ( exists("modTable") ) rm(modTable)
for ( i in outcomesWithoutVar ) {
modTable = safe_analyze_moderators(  .dat = dat,
yi.name = i,
# below assumes a standardized naming convention for
vi.name = NA,
# cut out the "pw." part of outcome name
analysis.label = strsplit(i, "[.]")[[1]][2],
modVars = modVars,
n.tests = length(modVars),
digits = 2 )
}
# for some reason, the FE problems get deleted
View(modTable)
table(modTable$Problems)
# @@think about ratio problem: maybe instead use difference, but controlling for original ES?
################################ TABLE: EXPT-LEVEL SUMMARIES OF PAIRWISE METRICS ################################
# TABLE of these metrics at the experiment level (~50 rows)
#bm
# quick look at results
# stringsWith( pattern = "pw", x = names(dat) )
#
takeMean = c("pw.PIRepInside",  # function:
"pw.PIRepInside.sens",
"pw.Porig",
"pw.PorigSens",
"pw.ratio",
"pw.PsigAgree1",
"pw.FEest")
# this is broken:
# res = dat %>% select(takeMean) %>%
#   mutate( across( .cols = everything(),
#                   .fns = mean) )
# x: vector of 0/1s
# @@note that this removes NAs
n_perc_string = function(x, digits = 0) {
if ( all( is.na(x) ) ) return("All missing")
x = x[!is.na(x)]
paste( sum(x), " (", round( 100 * mean(x), digits ), "%)", sep = "" )
}
n_perc_string( c(0,0,0,0,1,1,1,0,0) )
harmonic_p = function(x) {
library(harmonicmeanp)
if ( all( is.na(x) ) ) return(NA)
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
hmp.stat( x[ !is.na(x) ] )
}
#bm: instead of doing strings, should use numbers throughout and then post-process
#  that way we can use these in the plots
RE_string = function(yi, vi, digits = 2) {
mod = rma.uni(yi = yi,
vi = vi,
method = "REML")
paste( round( mod$b, digits ),
}
# aggregation fns:
# plain mean (ratio)
# count and percent (repinside, PsigAGree)
# FE analysis (origES2, repES2, FEest)
# harmonic mean p-value (porig)
expTable = dat %>% group_by(peID) %>%
summarise( nOutcomes = n(),
FEEst
Ratio = round( mean(pw.ratio), 2 ),
PIRepInside = n_perc_string(pw.PIRepInside),
PIRepInside.sens = n_perc_string(pw.PIRepInside.sens),
# @@note: better use p.hmp here becuase it's asymptotically exact,
#  but it was giving error messages
Porig = harmonic_p( pw.Porig ),
Porig.sens = harmonic_p( pw.PorigSens ),
# overall proportion (within this experiment) expected to agree
# @@insert actual sig agreement
SigAgree = n_perc_string( repSignif == origSignif & repDirection == origDirection),
PercSigAgree1 = paste( round( 100 * mean(pw.PsigAgree1), 0 ), "%", sep ="" )
)
View(expTable)
#################################### FOREST PLOT ###################################
# great info on dumbbell plot in ggplot:
# https://towardsdatascience.com/create-dumbbell-plots-to-visualize-group-differences-in-r-3536b7d0a19a
library(ggalt)
library(tidyverse)
dp = droplevels( dat %>% dplyr::filter( !is.na(origES2) & !is.na(repES2) & ES2type != "" ) %>%
dplyr::filter(ES2type %in% c("Cohen's d", "Glass' delta", "Log hazard ratio", "Cohen's dz") ) )
# randomly sample for testing purposes
set.seed(2)
dp = dp %>% group_by(ES2type) %>% sample_n( 3, replace = TRUE )
#dp = dat[1:10,]
dp$plotID = dp$peoID # with eye toward functionizing
dat %>% dplyr::filter( !is.na(origES2) & !is.na(repES2) & ES2type != "" ) %>%
group_by(ES2type)
dat %>% dplyr::filter( !is.na(origES2) & !is.na(repES2) & ES2type != "" ) %>%
group_by(ES2type) %>%
summarise(n())
dim(dat)
cardio = sum(c(72,31,60,36,42,122))
cardio/60
lift = sum(c(32,36,25,30,28,3,20,38))
lift/60
load("/Users/mmathur/Dropbox/Personal computer/Independent studies/EValue package/evalue_package_git/EValue/data/soyMeta.RData")
soyMeta
load("/Users/mmathur/Dropbox/Personal computer/Independent studies/EValue package/evalue_package_git/EValue/data/soyMeta.RData")
soyMeta
#package = c( "EValue", "SimTimeVar", "NRejections", "MetaUtility", "Replicate", "PublicationBias" )
package = "EValue"
cran_downloads(when = "last-week", package = package)
library(devtools)
install_github("metacran/cranlogs")
library(cranlogs)
#package = c( "EValue", "SimTimeVar", "NRejections", "MetaUtility", "Replicate", "PublicationBias" )
package = "EValue"
cran_downloads(when = "last-week", package = package)
d = cran_downloads(from = "2019-01-01",
to = "2019-12-31",
package = package)
library(ggplot2)
ggplot( data = d, aes( x = date, y = count, color = package) ) +
geom_line() +
geom_hline( yintercept = median(d$count), lty = 2, color = "red" ) +
ylab("Daily downloads") +
theme_classic()
# total for the year
sum(d$count)
# count by package
library(dplyr)
d %>% group_by(package) %>%
summarise( yr.total = sum(count) ) %>%
arrange( desc(yr.total) )
8066/321
#package = c( "EValue", "SimTimeVar", "NRejections", "MetaUtility", "Replicate", "PublicationBias" )
package = "ggplot2"
cran_downloads(when = "last-week", package = package)
d = cran_downloads(from = "2019-01-01",
to = "2019-12-31",
package = package)
d
# total for the year
sum(d$count)
x = 9889742
#package = c( "EValue", "SimTimeVar", "NRejections", "MetaUtility", "Replicate", "PublicationBias" )
package = "EValue"
d = cran_downloads(from = "2019-01-01",
to = "2019-12-31",
package = package)
# total for the year
sum(d$count)
8066/x
mean(c(3,4,4.5,5,4,5,4))
mean(c(4,3,2,2,5,2.5,2.5))
mean(c(4,4,3,2,5,4,3))
6.05*60/(8.25)
sum(c(65, 30,32,5,45,127))/60
sum(c(65, 30,22,5,45,127))/60
4.9*(60/8)
4.9*(60/8.1)
4.9*(60/8.25)
sum(c(24,39,33,32,30,3,47,21,3,36,45))/60
mean(c(5,5,5,4,3,4,4.5))
mean(c(4,3.5,2.5,4,4,5,3.5))
mean(c(2,2,2.5,2.5,4,5,4))
